{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import skimage.exposure\n",
    "import skimage.transform\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read training set info and make train/val split\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "N_CLASSES = len(df.whaleID.unique())\n",
    "CLASS_IX = {ID: i for i, ID in enumerate(df.whaleID.unique())}\n",
    "\n",
    "#train_ix, val_ix = sklearn.cross_validation.train_test_split(range(len(df)))\n",
    "train_ix = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to load and preprocess image with random distortions\n",
    "\n",
    "# expects input images cropped to face region, 384x384\n",
    "DATA_DIR = '../data/traincrops'\n",
    "\n",
    "def prep_image(fn, seed=None):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(4294967295)\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    im = plt.imread('{}/{}'.format(DATA_DIR, fn))\n",
    "\n",
    "    # random adjustment of gamma\n",
    "    im = skimage.exposure.adjust_gamma(im, rng.uniform(0.5, 1.5))\n",
    "\n",
    "    # random crop of each border\n",
    "    x1, x2, y1, y2 = rng.randint(1, 48, 4)\n",
    "    im = im[y1:-y2, x1:-x2]\n",
    "    \n",
    "    # scale cropped region to square 320x320\n",
    "    im = skimage.transform.resize(im, (64, 64))\n",
    "    \n",
    "    im = im - 0.5\n",
    "\n",
    "    # convert axes to bc01\n",
    "    im = np.transpose(im, (2, 0, 1))[np.newaxis]\n",
    "\n",
    "    return lasagne.utils.floatX(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a minibatch of augmented images and labels\n",
    "\n",
    "def batch(ix, batch_size, seed=None):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(4294967295)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    seeds = rng.randint(0, 4294967295, batch_size)\n",
    "    \n",
    "    image_ix = rng.choice(ix, batch_size)\n",
    "    fns = (df.ix[i].Image for i in image_ix)\n",
    "    images = [prep_image(fn, seed) for fn, seed in zip(fns, seeds)]\n",
    "    images = np.concatenate(images)\n",
    "    \n",
    "    labels = np.array([CLASS_IX[df.whaleID[i]] for i in image_ix]).astype('int32')\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Context manager to generate batches in the background via a process pool\n",
    "\n",
    "import uuid, os, pickle, hashlib\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "class BatchGenCM:\n",
    "    def __init__(self, batch_fn, ix, batch_size, seed=None, num_workers=8):\n",
    "        self.batch_fn = batch_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.ix = ix\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(4294967295)\n",
    "        self.seed = str(seed)\n",
    "        self.id = uuid.uuid4()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.jobq = Queue(maxsize=self.num_workers)\n",
    "        self.doneq = Queue()\n",
    "        self.processes = []\n",
    "        self.current_batch = 0\n",
    "        self.finished_batches = []\n",
    "        \n",
    "        def f(batch_fn, ix, batch_size):\n",
    "            while True:\n",
    "                n = self.jobq.get()\n",
    "                if n is None:\n",
    "                    break\n",
    "                seed = int(hashlib.md5(self.seed + str(n)).hexdigest(), 16) % 4294967295\n",
    "                batch = batch_fn(ix, batch_size, seed)\n",
    "                pickle.dump(batch, open('/run/shm/{}-{}'.format(self.id, n), 'w'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                self.doneq.put(n)\n",
    "        \n",
    "        for i in range(self.num_workers):\n",
    "            self.jobq.put(i)\n",
    "\n",
    "            p = Process(target=f, args=(self.batch_fn, self.ix, self.batch_size))\n",
    "            self.processes.append(p)\n",
    "            p.start()        \n",
    "\n",
    "        return self\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        n = self.current_batch\n",
    "        while n not in self.finished_batches:\n",
    "            i = self.doneq.get()\n",
    "            self.finished_batches.append(i)\n",
    "        \n",
    "        fn = '/run/shm/{}-{}'.format(self.id, n)\n",
    "        batch = pickle.load(open(fn))\n",
    "        os.system('rm {}'.format(fn))\n",
    "\n",
    "        self.jobq.put(n + self.num_workers)        \n",
    "        self.current_batch += 1\n",
    "        return batch\n",
    "            \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        for _ in range(self.num_workers):\n",
    "            self.jobq.put(None)\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        while not self.doneq.empty():\n",
    "            _ = next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "#from lasagne.layers.dnn import Conv2DDNNLayer as Conv\n",
    "#from lasagne.layers.dnn import Pool2DDNNLayer as Pool\n",
    "#from lasagne.layers.corrmm import Conv2DMMLayer as Conv\n",
    "#from lasagne.layers import Pool2DLayer as Pool\n",
    "from lasagne.layers import Conv2DLayer as Conv\n",
    "from lasagne.layers import MaxPool2DLayer as Pool\n",
    "\n",
    "from lasagne.layers import batch_norm\n",
    "\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.init import GlorotUniform\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "def build_model(batch_size, input_width, input_height):\n",
    "    net = {}\n",
    "    activation = lasagne.nonlinearities.rectify\n",
    "\n",
    "    nfilt = 32\n",
    "\n",
    "    l = InputLayer((batch_size, 3, input_width, input_height))\n",
    "    net['input'] = l\n",
    "    l = batch_norm(Conv(l, nfilt, 2, stride=2, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "\n",
    "    for _ in range(2):\n",
    "        if nfilt >= 128:\n",
    "            nfilt = 128\n",
    "        l = batch_norm(Conv(l, nfilt, 3, stride=1, pad=0, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "        l = Pool(l, 2, stride=2)\n",
    "        nfilt *= 2\n",
    "    l = batch_norm(Conv(l, nfilt, 3,stride=1, pad=0, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "        \n",
    "    l = DropoutLayer(l, p=0.8)\n",
    "    l = DenseLayer(l, num_units=447, nonlinearity=softmax, W=GlorotUniform(gain='relu'))\n",
    "    net['output'] = l\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = build_model(32, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "prob = lasagne.layers.get_output(net['output'], X)\n",
    "loss = T.mean(lasagne.objectives.categorical_crossentropy(prob, y))\n",
    "acc = T.mean(lasagne.objectives.categorical_accuracy(prob, y))\n",
    "\n",
    "test_prob = lasagne.layers.get_output(net['output'], X, deterministic=True)\n",
    "test_loss = T.mean(lasagne.objectives.categorical_crossentropy(test_prob, y))\n",
    "test_acc = T.mean(lasagne.objectives.categorical_accuracy(test_prob, y))\n",
    "\n",
    "params = lasagne.layers.get_all_params(net['output'], trainable=True)\n",
    "\n",
    "updates = lasagne.updates.adadelta(loss, params, learning_rate=1.0, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_prob = theano.function([X], test_prob)\n",
    "f_train = theano.function([X, y], [loss, acc], updates=updates)\n",
    "f_val = theano.function([X, y], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 30, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "  File \"<ipython-input-5-709116d33fd8>\", line 26, in f\n",
      "    batch = batch_fn(ix, batch_size, seed)\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "    n = self.jobq.get()\n",
      "  File \"<ipython-input-4-281c8b6283e7>\", line 11, in batch\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 117, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    images = [prep_image(fn, seed) for fn, seed in zip(fns, seeds)]\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "    res = self._recv()\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "    self._rlock.acquire()\n",
      "  File \"<ipython-input-3-99d8b57f52dc>\", line 21, in prep_image\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    im = skimage.transform.resize(im, (64, 64))\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/site-packages/skimage/transform/_warps.py\", line 107, in resize\n",
      "    preserve_range=preserve_range)\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/site-packages/skimage/transform/_geometric.py\", line 1395, in warp\n",
      "    _clip_warp_output(image, warped, order, mode, cval, clip)\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/site-packages/skimage/transform/_geometric.py\", line 1145, in _clip_warp_output\n",
      "    min_val = input_image.min()\n",
      "  File \"/home/cuda/anaconda2/envs/ff_env/lib/python2.7/site-packages/numpy/core/_methods.py\", line 29, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5b8122766e9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_BATCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mloss_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_bg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch {:03} - tr: {:.04f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN_BATCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-709116d33fd8>\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoneq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cuda/anaconda2/envs/ff_env/lib/python2.7/multiprocessing/queues.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# After 300 epochs, should be around 1.9-2.0 val loss\n",
    "BATCH_SIZE = 32\n",
    "N_BATCH = len(train_ix) / BATCH_SIZE\n",
    "N_VAL_BATCH = 10\n",
    "\n",
    "lasagne.random.set_rng(np.random.RandomState(SEED))\n",
    "with BatchGenCM(batch, train_ix, 32, seed=SEED) as train_bg:\n",
    "    for epoch in range(2):\n",
    "        loss_train = 0\n",
    "        for _ in range(N_BATCH):\n",
    "            loss_batch, _ = f_train(*next(train_bg))\n",
    "            loss_train += loss_batch\n",
    "        print('epoch {:03} - tr: {:.04f}'.format(epoch, loss_train/N_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pvs = lasagne.layers.get_all_param_values(net['output'])\n",
    "pickle.dump(pvs, open('./cls_seed{}_300_epochs.pkl'.format(SEED),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model(None, 320, 320)\n",
    "lasagne.layers.set_all_param_values(net['output'], pvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Make Predictions on Test Image Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/testcrops_filteredB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_test_image(fn, seed):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    im = plt.imread('{}/{}'.format(DATA_DIR, fn))\n",
    "    im = im/255.\n",
    "    if min(im.shape[:2]) < 384:\n",
    "        im = skimage.transform.resize(im, (384, 384))\n",
    "    im = skimage.exposure.adjust_gamma(im, rng.uniform(0.5, 1.5))\n",
    "    x1, x2, y1, y2 = rng.randint(1, 48, 4)\n",
    "    im = im[y1:-y2, x1:-x2]\n",
    "    im = skimage.transform.resize(im, (320, 320))\n",
    "    \n",
    "    im = im - 0.5\n",
    "\n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "\n",
    "    return lasagne.utils.floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "p = []\n",
    "for i in range(len(df)):\n",
    "    seeds = np.random.randint(0, 4294967295, 64)\n",
    "    im = np.concatenate(joblib.Parallel(n_jobs=8)(joblib.delayed(prep_test_image)(df.Image[i], s) for s in seeds))\n",
    "    p.append(f_prob(im).mean(0))\n",
    "p = np.array(p)\n",
    "\n",
    "ix_map = np.array([CLASS_IX[i] for i in df.columns[1:]])\n",
    "df.ix[:, 1:] = p[:, ix_map]\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
